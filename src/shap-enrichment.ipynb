{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom typing import List, Tuple\n\nfrom .utils import processed_shap_path, slm_training_data_path, ensure_dir, DATA_PROCESSED_DIR\n\n\n# 1) Parse shap_summary => list of (feature, impact)\ndef parse_shap_summary(summary: str) -> List[Tuple[str, float]]:\n    \"\"\"\n    Parse a string like:\n        \"Top factors: mins_since_prev_txn +0.049, city_enc -0.047, ...\"\n    into:\n        [(\"mins_since_prev_txn\", 0.049), (\"city_enc\", -0.047), ...]\n    \"\"\"\n    if not isinstance(summary, str):\n        return []\n    if \"Top factors\" not in summary:\n        return []\n    parts = re.findall(r\"([A-Za-z0-9_]+)\\s*([+-]?\\d+\\.\\d+)\", summary)\n    pairs: List[Tuple[str, float]] = [(p[0], float(p[1])) for p in parts]\n    return pairs\n\n\n# 2) Map features -> human reasons (your feature_reason_map)\nfeature_reason_map = {\n    \"amount\": \"unusually high or irregular transaction amount\",\n    \"ratio\": \"transaction amount deviation from usual spending pattern\",\n    \"cnt\": \"sudden spike in transaction frequency\",\n    \"freq\": \"elevated spending frequency\",\n    \"time\": \"transaction at unusual timing\",\n    \"mins\": \"irregular timing pattern\",\n    \"city\": \"unexpected city/location change\",\n    \"country\": \"unusual country for this customer\",\n    \"mcc\": \"merchant category atypical for this customer\",\n    \"device\": \"new or rare device\",\n    \"merchant\": \"unusual merchant behavior\",\n}\n\n\ndef make_anomaly_summary_from_pairs(pairs: List[Tuple[str, float]]) -> str:\n    \"\"\"\n    Create a human-friendly 'silver label' explanation from top SHAP pairs.\n    \"\"\"\n    if not isinstance(pairs, list) or len(pairs) == 0:\n        return \"Regular transaction.\"\n\n    explanations = []\n    for feat, impact in pairs[:3]:\n        matched = False\n        for key, reason in feature_reason_map.items():\n            if key in feat:\n                explanations.append(reason)\n                matched = True\n                break\n        if not matched:\n            explanations.append(f\"irregularity in {feat.replace('_', ' ')}\")\n\n    reason_text = \", and \".join(explanations)\n    return f\"This transaction appears suspicious due to {reason_text}.\"\n\n\n# 3) Lightweight paraphrase templates (to avoid template overfitting)\ndef paraphrase_variants(plain_text: str):\n    templates = [\n        lambda t: t,\n        lambda t: t.replace(\"This transaction appears suspicious due to\", \"Flagged because of\"),\n        lambda t: t.replace(\"This transaction appears suspicious due to\", \"Suspicion arises from\"),\n        lambda t: t.replace(\"This transaction appears suspicious due to\", \"Potential anomaly:\"),\n    ]\n    variants = []\n    for fn in templates[:3]:\n        variants.append(fn(plain_text))\n    return variants\n\n\n# 4) Generative prompt builder for SLM\ndef build_generative_prompt_from_row(row: pd.Series, top_pairs: List[Tuple[str, float]]) -> str:\n    # Top 5 shap drivers with sign and magnitude\n    shap_text = \", \".join(\n        [f\"{feat.replace('_',' ')} ({impact:+.3f})\" for feat, impact in top_pairs[:5]]\n    ) if top_pairs else \"none\"\n\n    prompt = (\n        \"You are a fraud investigator assistant. Generate a concise 1–2 line explanation \"\n        \"for why the transaction may be anomalous. Use professional language suitable for case notes.\\n\\n\"\n        \"Transaction Details:\\n\"\n        f\"- Amount: ${row.get('txn_amount')}\\n\"\n        f\"- Location: {row.get('txn_city')}, {row.get('txn_country')}\\n\"\n        f\"- Minutes since previous transaction: {row.get('mins_since_prev_txn')}\\n\"\n        f\"- Transactions in last 24 hours: {row.get('txn_cnt_inlast1440mins')}\\n\\n\"\n        \"Top SHAP Drivers:\\n\"\n        f\"{shap_text}\\n\\n\"\n        \"Instruction: Using the SHAP drivers, describe the observable anomaly in 1–2 sentences. \"\n        \"Do not enumerate features; produce a single natural-language explanation suitable for investigators.\"\n    )\n    return prompt\n\n\ndef build_slm_dataset() -> pd.DataFrame:\n    \"\"\"\n    Load SHAP-enriched dataframe, build:\n      - _top_shap_pairs: list[(feature, impact)]\n      - target_text: silver explanation from SHAP\n      - input_text: generative prompt\n    with paraphrased targets to encourage diverse generative behavior.\n    \"\"\"\n    df = pd.read_csv(processed_shap_path())\n\n    # 1) Parse shap_summary -> _top_shap_pairs so we keep numeric +/- signs\n    df[\"_top_shap_pairs\"] = df[\"shap_summary\"].apply(parse_shap_summary)\n\n    # 2) Build base silver target\n    df[\"target_text\"] = df[\"_top_shap_pairs\"].apply(make_anomaly_summary_from_pairs)\n\n    # 3) Expand with paraphrases (each row -> 1–3 samples)\n    rows = []\n    for _, r in df.iterrows():\n        pairs = r[\"_top_shap_pairs\"]\n        base = r[\"target_text\"]\n        variants = paraphrase_variants(base)\n\n        for variant in variants:\n            rows.append({\n                \"txn_id\": r.get(\"txn_id\"),\n                \"txn_amount\": r.get(\"txn_amount\"),\n                \"txn_city\": r.get(\"txn_city\"),\n                \"txn_country\": r.get(\"txn_country\"),\n                \"mins_since_prev_txn\": r.get(\"mins_since_prev_txn\"),\n                \"txn_cnt_inlast1440mins\": r.get(\"txn_cnt_inlast1440mins\"),\n                \"_top_shap_pairs\": pairs,\n                \"input_text\": None,  # we fill after\n                \"target_text\": variant,\n            })\n\n    df_slm = pd.DataFrame(rows)\n\n    # 4) Build prompts\n    def _build_prompt(row):\n        pairs = row[\"_top_shap_pairs\"]\n        return build_generative_prompt_from_row(row, pairs)\n\n    df_slm[\"input_text\"] = df_slm.apply(_build_prompt, axis=1)\n    df_slm[\"target_text\"] = df_slm[\"target_text\"].astype(str)\n\n    ensure_dir(DATA_PROCESSED_DIR)\n    df_slm.to_csv(slm_training_data_path(), index=False)\n    print(f\"SLM training dataset saved to {slm_training_data_path()}, shape {df_slm.shape}\")\n\n    return df_slm\n\n\nif __name__ == \"__main__\":\n    build_slm_dataset()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}